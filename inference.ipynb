{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "import commons\n",
    "import utils\n",
    "# from data_utils import TextAudioLoader, TextAudioCollate, TextAudioSpeakerLoader, TextAudioSpeakerCollate\n",
    "from models import SynthesizerTrn\n",
    "from text.symbols import symbols\n",
    "from text import  cleaned_text_to_sequence\n",
    "from utils import load_wav_to_torch\n",
    "from mel_processing import spectrogram_torch\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "from text.cleaners import _clean_text\n",
    "\n",
    "\n",
    "config_path = 'configs/config.json'\n",
    "hps = utils.get_hparams_from_file(config_path)\n",
    "\n",
    "net_g = SynthesizerTrn(\n",
    "    len(symbols),\n",
    "    hps.data.filter_length // 2 + 1,\n",
    "    hps.train.segment_size // hps.data.hop_length,\n",
    "    n_speakers=hps.data.n_speakers,\n",
    "    **hps.model).cuda()\n",
    "_ = net_g.eval()\n",
    "\n",
    "def get_text(text, hps):\n",
    "    cleaned_text, lang = _clean_text(text)\n",
    "    print(cleaned_text)\n",
    "    text_norm = cleaned_text_to_sequence(cleaned_text)\n",
    "    if hps.data.add_blank:\n",
    "        text_norm,lang = commons.intersperse_with_language_id(text_norm,lang, 0)\n",
    "    text_norm = torch.LongTensor(text_norm)\n",
    "    lang = torch.LongTensor(lang)\n",
    "    return text_norm,lang,cleaned_text\n",
    "\n",
    "dev = \"cuda\"\n",
    "net_g = net_g.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stn_tst = get_text(\"VITS is Awesome!\", hps)\n",
    "# with torch.no_grad():\n",
    "#     x_tst = stn_tst.cuda().unsqueeze(0)\n",
    "#     x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).cuda()\n",
    "#     sid = torch.LongTensor([4]).cuda()\n",
    "#     audio = net_g.infer(x_tst, x_tst_lengths, sid=sid, noise_scale=.667, noise_scale_w=0.8, length_scale=1)[0][0,0].data.cpu().float().numpy()\n",
    "# ipd.display(ipd.Audio(audio, rate=hps.data.sampling_rate, normalize=False))\n",
    "_ = utils.load_checkpoint(utils.latest_checkpoint_path(\"logs/snac/\", \"G_*.pth\"), net_g,\n",
    "                      None, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"[ZH]你说的对，但是《原神》是由米哈游自主研发的一款全新开放世界冒险游戏。游戏发生在一个被称作提瓦特的幻想世界，在这里，被神选中的人将被授予「神之眼」，导引元素之力。你将扮演一位名为「旅行者」的神秘角色，在自由的旅行中邂逅性格各异、能力独特的同伴们，和他们一起击败强敌，找回失散的亲人[ZH]\"\n",
    "text = \"[ZH]你说的对，但是《原神》是由米哈游自主研发的一款全新开放世界冒险游戏。游戏发生在一个被称作提瓦特的幻想世界，在这里，被神选中的人将被授予「神之眼」，导引元素之力。[ZH]\"\n",
    "text = \"[ZH]你说的对，但是原神是由米哈游自主研发的一款全新开放世界冒险游戏。[ZH]\"\n",
    "spk = \"paimon\"\n",
    "text_norm,lang,_ = get_text(text, hps)\n",
    "\n",
    "text_norm = torch.LongTensor(text_norm)\n",
    "lang = torch.LongTensor(lang)\n",
    "x_tst = text_norm.to(dev).unsqueeze(0)\n",
    "lang = lang.to(dev).unsqueeze(0)\n",
    "x_tst_lengths = torch.LongTensor([text_norm.size(0)]).to(dev)\n",
    "speaker_id = torch.LongTensor([0]).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latents = []\n",
    "for i in range(4):\n",
    "    with torch.no_grad():\n",
    "        y_hat,_,_,_,latent =net_g.infer(x_tst, x_tst_lengths, lang,None,\n",
    "                                       sid=speaker_id,  predict_style=True, style_noise_scale=1.4)\n",
    "        audio = y_hat[0, :, :].cpu().numpy()\n",
    "        ipd.display(ipd.Audio(audio, rate=hps.data.sampling_rate, normalize=False))\n",
    "        latents.append(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "za = latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "zb = latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ratio in [0, 0.2,0.4, 0.6,0.8, 1]:\n",
    "    z = za * (1-ratio) + zb * ratio\n",
    "    with torch.no_grad():\n",
    "        y_hat,_,_,_,latent =net_g.infer(x_tst, x_tst_lengths, lang,None,\n",
    "                                       sid=speaker_id,  predict_style=True, manual_latent=z)\n",
    "        audio = y_hat[0, :, :].cpu().numpy()\n",
    "        ipd.display(ipd.Audio(audio, rate=hps.data.sampling_rate, normalize=False))\n",
    "        # latents.append(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mel_processing import spectrogram_torch\n",
    "from utils import load_wav_to_torch, load_filepaths_and_text\n",
    "import librosa\n",
    "import wav2ssl\n",
    "ssl_type = \"chinese_hubert\"\n",
    "\n",
    "ssl_model = wav2ssl.get_ssl_model(ssl_type).to(dev)\n",
    "\n",
    "def get_audio(filename):\n",
    "    import utils\n",
    "    wav16k, sr = librosa.load(filename, sr=16000)\n",
    "    wav16k = torch.from_numpy(wav16k).to(dev)\n",
    "    feats = wav2ssl.get_ssl_content(ssl_type, ssl_model, wav16k)\n",
    "    \n",
    "    audio, sampling_rate = librosa.load(filename, sr=44100)\n",
    "    audio = torch.FloatTensor(audio)\n",
    "    if sampling_rate != hps.data.sampling_rate:\n",
    "        raise ValueError(\"{} {} SR doesn't match target {} SR\".format(\n",
    "            sampling_rate, hps.data.sampling_rate))\n",
    "    audio_norm = audio / hps.data.max_wav_value\n",
    "    audio_norm = audio_norm.unsqueeze(0)\n",
    "    spec_filename = filename.replace(\".wav\", \".spec.pt\")\n",
    "    if os.path.exists(spec_filename):\n",
    "        spec = torch.load(spec_filename)\n",
    "    else:\n",
    "        spec = spectrogram_torch(audio_norm, hps.data.filter_length,\n",
    "                                 hps.data.sampling_rate, hps.data.hop_length, hps.data.win_length,\n",
    "                                 center=False)\n",
    "        spec = torch.squeeze(spec, 0)\n",
    "        torch.save(spec, spec_filename)\n",
    "    feats = F.interpolate(feats, size=spec.shape[-1], mode=\"nearest\").squeeze(0)\n",
    "\n",
    "\n",
    "    \n",
    "    return feats, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src = \"dataset/SSB1125/SSB11250140.wav\"\n",
    "src = \"test.wav\"\n",
    "# src = \"dataset/paimon/vo_XMAQ014_6_paimon_11.wav\"\n",
    "tgt = \"dataset/paimon/vo_XMAQ014_6_paimon_11.wav\"\n",
    "spec_tgt = get_audio(tgt)[0].unsqueeze(0).to(dev)\n",
    "spec_tgt_lengths = torch.LongTensor([spec_tgt.size(-1)]).to(dev)\n",
    "spec_src = get_audio(src)[0].unsqueeze(0).to(dev)\n",
    "spec_src_lengths = torch.LongTensor([spec_src.size(-1)]).to(dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_hat,_,_,_,latent =net_g.infer(x_tst, x_tst_lengths, lang,spec_src,\n",
    "                                   sid=speaker_id,  predict_style=False)\n",
    "    audio = y_hat[0, :, :].cpu().numpy()\n",
    "    ipd.display(ipd.Audio(audio, rate=hps.data.sampling_rate, normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_hat,_,_  =net_g.voice_conversion(spec_src,spec_src_lengths,spec_tgt)\n",
    "    audio = y_hat[0, :, :].cpu().numpy()\n",
    "    ipd.display(ipd.Audio(audio, rate=hps.data.sampling_rate, normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spec_src_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
